{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WASTE MANAGEMENT\n",
    "PROBLEM\n",
    "\n",
    "Waste management is a big problem in our country. Most of the wastes end up in landfills. This leads to many issues like\n",
    "\n",
    "Increase in landfills\n",
    "Eutrophication\n",
    "Consumption of toxic waste by animals\n",
    "Increase in toxins\n",
    "Land, water and air pollution\n",
    "APPROACH\n",
    "\n",
    "Analysed the components of household waste\n",
    "Segregated into two classes (Organic and recyclable)\n",
    "Automated the process by using IOT and machine learning\n",
    "Reduce toxic waste ending in landfills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 19:54:53.044240: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-16 19:54:53.044297: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib \n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import skimage.io\n",
    "import tensorflow \n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_o = glob.glob('Waste_DATASET/TRAIN/O/*.jpg')\n",
    "a = len(train_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r = glob.glob('Waste_DATASET/TRAIN/R/*.jpg')\n",
    "b = len(train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nos of training samples: 22564\n"
     ]
    }
   ],
   "source": [
    "# Total training images \n",
    "print(\"Nos of training samples: {}\".format(a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0 / 255.0,\n",
    "                                   zoom_range = 0.4,\n",
    "                                   rotation_range = 10,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = True,\n",
    "                                   validation_split = 0.2)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1.0 / 255.0,\n",
    "                                   validation_split = 0.2)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1.0 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18052 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_dataset  = train_datagen.flow_from_directory(directory = 'Waste_DATASET/TRAIN',\n",
    "#                                                    target_size = (224,224),\n",
    "#                                                    class_mode = 'binary',\n",
    "#                                                    batch_size = 128, \n",
    "#                                                    subset = 'training')\n",
    "\n",
    "train_dataset  = train_datagen.flow_from_directory(directory = 'Waste_DATASET/TRAIN',\n",
    "                                                   target_size = (224,224),\n",
    "                                                   class_mode = 'binary',\n",
    "                                                   batch_size = 64, \n",
    "                                                   subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# valid_dataset = valid_datagen.flow_from_directory(directory = 'Waste_DATASET/TRAIN',\n",
    "#                                                   target_size = (224,224),\n",
    "#                                                   class_mode = 'binary',\n",
    "#                                                   batch_size = 128, \n",
    "#                                                   subset = 'validation')\n",
    "\n",
    "valid_dataset = valid_datagen.flow_from_directory(directory = 'Waste_DATASET/TRAIN',\n",
    "                                                  target_size = (224,224),\n",
    "                                                  class_mode = 'binary',\n",
    "                                                  batch_size = 64, \n",
    "                                                  subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'R': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class Indices \n",
    "\n",
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Viewing Images\n",
    "\n",
    "# # fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,20))\n",
    "\n",
    "# for i in tqdm(range(12)):\n",
    "#     rand1 = np.random.randint(len(train_dataset))\n",
    "#     rand2 = np.random.randint(128)\n",
    "#     ax[i].imshow(train_dataset[rand1][0][rand2])\n",
    "#     ax[i].axis('off')\n",
    "#     label = train_dataset[rand1][1][rand2]\n",
    "#     if label == 1:\n",
    "#         ax[i].set_title('Recycle Waste')\n",
    "#     else:\n",
    "#         ax[i].set_title('Organic Waste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model\n",
    "\n",
    "base_model = VGG16(input_shape=(224,224,3), \n",
    "                   include_top=False,\n",
    "                   weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing Layers \n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Layers\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compile \n",
    "\n",
    "OPT    = tensorflow.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=[tensorflow.keras.metrics.AUC(name = 'auc')],\n",
    "              optimizer=OPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Callbacks\n",
    "\n",
    "filepath = './best_weights.hdf5'\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'val_auc', \n",
    "                              mode = 'max' , \n",
    "                              patience = 5,\n",
    "                              verbose = 1)\n",
    "\n",
    "checkpoint    = ModelCheckpoint(filepath, \n",
    "                                monitor = 'val_auc', \n",
    "                                mode='max', \n",
    "                                save_best_only=True, \n",
    "                                verbose = 1)\n",
    "\n",
    "\n",
    "callback_list = [earlystopping, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Fitting \n",
    "\n",
    "model_history=model.fit(train_dataset,\n",
    "                        validation_data=valid_dataset,\n",
    "                        epochs = 10,\n",
    "                        callbacks = callback_list,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the model loss\n",
    "\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('VGG16 Model Loss', FontSize = 16)\n",
    "plt.ylabel('Loss', FontSize = 16)\n",
    "plt.xlabel('Epoch', FontSize = 16)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize models auc\n",
    "\n",
    "plt.plot(model_history.history['auc'])\n",
    "plt.plot(model_history.history['val_auc'])\n",
    "plt.title('VGG16 Model Accuracy', FontSize = 16)\n",
    "plt.ylabel('Accuracy',FontSize = 16)\n",
    "plt.xlabel('Epoch',FontSize = 16)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(model_history.history['val_auc']), max(model_history.history['val_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data \n",
    "\n",
    "test_data = test_datagen.flow_from_directory(directory = 'Waste_DATASET/TEST',\n",
    "                                             target_size = (224,224),\n",
    "                                             class_mode = 'binary',\n",
    "                                             batch_size = 128)\n",
    "predictions = model.predict(test_data)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "## Create the Confusion Matrix out of the Actual and Predicted Data.\n",
    "cm = confusion_matrix(test_data.class_indices , predictions)\n",
    "# scale the font size and color of the map\n",
    "ax = sns.set(font_scale=1) #edited as suggested\n",
    "ax = sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"g\");  # annot=True to annotate cells\n",
    "## Print the Confusion Matrix\n",
    "print(cm)\n",
    "ax.set_title('Confusion Matrix', size=20);\n",
    "ax.set_xlabel('Predicted Labels',size=20)\n",
    "ax.set_ylabel('Actual Labels', size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "print('Accuracy on testing set:', accuracy_score(test_data.class_indices, predictions)*100, \"%\")\n",
    "print('Precision on testing set:', precision_score(test_data.class_indices, predictions, average = 'weighted')*100, \"%\")\n",
    "print('Recall on testing set:', recall_score(test_dataset.class_indices, predictions, average = 'weighted')*100, \"%\")\n",
    "# F1 Score = 2*((precision*recall)/(precision+recall))\n",
    "precision_test = precision_score(test_data.class_indices, predictions, average = 'weighted')\n",
    "recall_test = recall_score(test_data.class_indices, predictions, average = 'weighted')\n",
    "print('F1 on testing set:' , 2*((precision_test*recall_test)/(precision_test+recall_test)) )\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('F1 score is',f1_score(test_data.class_indices, predictions, average = 'weighted') *100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC - AUC Score\n",
    "predicted_probab =model.predict(test_data)\n",
    "# predicted_probab\n",
    "n_class = 2\n",
    "\n",
    "for i in range(n_class):    \n",
    "    print(\"ROC- AUC score is\", roc_auc_score(test_data.class_indices, predicted_probab[:,i], multi_class='ovr')*100)\n",
    "    \n",
    "# print(\"ROC- AUC score is\", roc_auc_score( test.Labels, predicted_probab, multi_class='ovr')*100)\n",
    "print(\"ROC- AUC score is\", roc_auc_score( test_data.class_indices, predicted_probab, multi_class='ovr')*100)\n",
    "from sklearn import metrics\n",
    "\n",
    "# roc curve for classes\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "\n",
    "n_class = 2\n",
    "\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = metrics.roc_curve(test_data.class_indices, predicted_probab[:,i], pos_label=i)\n",
    "    \n",
    "# plotting    \n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
    "\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Multiclass ROC',dpi=300);   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Loss and AUC - Test Data \n",
    "\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case:1 - ORGANIC\n",
    "\n",
    "dic = test_data.class_indices\n",
    "idc = {k:v for v,k in dic.items()}\n",
    "\n",
    "img = load_img('Waste_DATASET/TEST/O/O_12650.jpg', target_size=(224,224))\n",
    "img = img_to_array(img)\n",
    "img = img / 255\n",
    "imshow(img)\n",
    "plt.axis('off')\n",
    "img = np.expand_dims(img,axis=0)\n",
    "answer = model.predict_proba(img)\n",
    "\n",
    "if answer[0][0] > 0.5:\n",
    "    print(\"The image belongs to Recycle waste category\")\n",
    "else:\n",
    "    print(\"The image belongs to Organic waste category \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case:2 - RECYCLE\n",
    "\n",
    "dic = test_data.class_indices\n",
    "idc = {k:v for v,k in dic.items()}\n",
    "\n",
    "img = load_img('Waste_DATASET/TEST/R/R_10011.jpg', target_size=(224,224))\n",
    "img = img_to_array(img)\n",
    "img = img / 255\n",
    "imshow(img)\n",
    "plt.axis('off')\n",
    "img = np.expand_dims(img,axis=0)\n",
    "answer = model.predict_proba(img)\n",
    "\n",
    "if answer[0][0] > 0.5:\n",
    "    print(\"The image belongs to Recycle waste category\")\n",
    "else:\n",
    "    print(\"The image belongs to Organic waste category \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCLUSION\n",
    "\n",
    "# 1. We were able to classify images properly having accuracy of 97.00% in training dataset.\n",
    "\n",
    "# 2. We acheived an accuracy of 95.60% on validation data and 94.98% accuracy on test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
